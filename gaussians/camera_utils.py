import torch as th
from torch import nn
import numpy as np


def getWorld2View(R, t):
    Rt = np.zeros((4, 4))
    Rt[:3, :3] = R.transpose()
    Rt[:3, 3] = t
    Rt[3, 3] = 1.0
    return np.float32(Rt)


def getWorld2View2(R, t, translate=np.array([0.0, 0.0, 0.0]), scale=1.0):
    Rt = th.zeros((4, 4))
    Rt[:3, :3] = R.T
    Rt[:3, 3] = t
    Rt[3, 3] = 1.0

    C2W = th.linalg.inv(Rt)
    cam_center = C2W[:3, 3]
    cam_center = (cam_center) * scale
    C2W[:3, 3] = cam_center
    Rt = th.linalg.inv(C2W)

    return Rt.float()


def getProjectionMatrix(znear, zfar, fovX, fovY):
    tanHalfFovY = th.tan((fovY / 2))
    tanHalfFovX = th.tan((fovX / 2))

    top = tanHalfFovY * znear
    bottom = -top
    right = tanHalfFovX * znear
    left = -right

    P = th.zeros(4, 4).cuda()

    z_sign = 1.0

    P[0, 0] = 2.0 * znear / (right - left)
    P[1, 1] = 2.0 * znear / (top - bottom)
    P[0, 2] = (right + left) / (right - left)
    P[1, 2] = (top + bottom) / (top - bottom)
    P[3, 2] = z_sign
    P[2, 2] = z_sign * zfar / (zfar - znear)
    P[2, 3] = -(zfar * znear) / (zfar - znear)
    return P


def fov2focal(fov, pixels):
    return pixels / (2 * math.tan(fov / 2))


def focal2fov(focal, pixels):
    return 2 * math.atan(pixels / (2 * focal))


def get_normals(points, neighborhood_size=50):
    return estimate_pointcloud_normals(points, neighborhood_size=neighborhood_size)
